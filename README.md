<!-- ================= BADGES ================= -->
<p align="center">
  <img src="https://img.shields.io/badge/Role-Data%20Engineer-blue" />
  <img src="https://img.shields.io/badge/Experience-4%2B%20Years-success" />
  <img src="https://img.shields.io/badge/Tech-Azure%20|%20Databricks%20|%20PySpark-informational" />
  <img src="https://img.shields.io/badge/Focus-Scalable%20Data%20Pipelines-orange" />
  <img src="https://img.shields.io/badge/Open%20to%20Opportunities-Yes-brightgreen" />
</p>

---

<!-- ================= HEADER ================= -->
<h1 align="center">Hi ğŸ‘‹, I'm Mangesh Yadav</h1>
<h3 align="center">Certified Data Engineer | Azure â€¢ Databricks â€¢ PySpark â€¢ Power BI</h3>

<p align="center">
ğŸ“ Nagpur, India &nbsp; | &nbsp;
ğŸ“§ <a href="mailto:Mangeshyadavv@gmail.com">Email</a> &nbsp; | &nbsp;
ğŸ”— <a href="https://www.linkedin.com/in/mangesh-yadav-Data-scientist">LinkedIn</a> &nbsp; | &nbsp;
ğŸ’» <a href="https://github.com/Mangesh-Yadav12">GitHub</a>
</p>


---

## ğŸ§  Professional Summary

I am a **Certified Data Engineer with 4+ years of experience** building scalable, production-grade data pipelines and analytics platforms using **Azure Databricks, PySpark, Delta Lake, and Azure Data Factory**.

I specialize in **modern data stacks, marketing data integration, lakehouse architecture, performance optimization**, and **business-driven analytics**.

---

## ğŸŒ Socials

<p>
<a href="https://www.linkedin.com/in/mangesh-yadav-Data-scientist">
<img src="https://img.shields.io/badge/LinkedIn-0A66C2?style=for-the-badge&logo=linkedin&logoColor=white"/>
</a>
<a href="mailto:Mangeshyadavv@gmail.com">
<img src="https://img.shields.io/badge/Email-EA4335?style=for-the-badge&logo=gmail&logoColor=white"/>
</a>
</p>

---


## ğŸ”‘ Impact at a Glance

- â±ï¸ Reduced data processing time by **87%** using PySpark & Databricks  
- ğŸ“‰ Cut manual reporting efforts by **60%** through automation  
- ğŸ“Š Enabled real-time insights across **6+ marketing platforms**  
- ğŸš€ Improved campaign engagement by **30%**

---

## ğŸ› ï¸ Tech Stack (Click to Expand)

<details>
<summary><strong>ğŸ§© Data Engineering</strong></summary>

- Azure Databricks  
- Azure Data Factory  
- Delta Lake & Delta Live Tables  
- Azure SQL, Synapse  
- Lakehouse Architecture  

</details>

<details>
<summary><strong>âš™ï¸ Programming & Querying</strong></summary>

- Python  
- PySpark  
- SQL  

</details>

<details>
<summary><strong>ğŸ“Š BI & Analytics</strong></summary>

- Power BI  
- Microsoft Fabric  
- Looker  

</details>

<details>
<summary><strong>ğŸ” Version Control</strong></summary>

- Git  
- GitHub  

</details>

---

## ğŸ’¼ Work Experience

<details>
<summary><strong>ğŸ¢ Data Engineer â€” Mediamint (Sep 2021 â€“ Apr 2025)</strong></summary>

### Data Engineering & Pipelines
- Designed and deployed scalable ETL pipelines using **Azure Databricks, Azure Data Factory, Fivetran, Azure SQL**
- Built Delta Lakeâ€“based lakehouse architecture supporting analytics and ML workloads
- Automated ingestion from **Facebook Ads, GA4, DV360, SA360, LinkedIn Ads, Mercado Libre**
- Reduced report generation time by **60%**

### Business Intelligence
- Built **10+ Power BI dashboards** for budget vs spend, campaign performance, and customer insights
- Created self-serve analytics tools, reducing manual reporting by **50%**
- Partnered with stakeholders to define KPIs and resolve data discrepancies

</details>

---

## ğŸš€ Featured Projects (Expandable)

<details>
<summary><strong>ğŸ“Œ Customer Segmentation Using Databricks</strong></summary>

**Tech:** Databricks | PySpark | Delta Lake | Azure Data Lake | Power BI  

- Built scalable ETL pipelines for **10M+ customer records**
- Performed feature engineering using PySpark
- Stored curated datasets in Delta Lake
- Developed dashboards to visualize customer clusters
- Enabled **30% increase in marketing engagement**

</details>

<details>
<summary><strong>ğŸ“Œ Budget vs Spend Campaign Analytics Dashboard</strong></summary>

**Tech:** Power BI | Delta Lake | Microsoft Fabric  

- Developed real-time dashboards across multiple marketing platforms
- Unified campaign KPIs and attribution models
- Reduced manual reporting efforts by **60%**

</details>

<details>
<summary><strong>ğŸ“Œ Modern Data Stack Implementation</strong></summary>

**Tech:** Azure Databricks | PySpark | Delta Lake | DLT | Streaming  

- Implemented **Medallion Architecture (Bronze, Silver, Gold)**
- Built batch & streaming pipelines using Autoloader & Structured Streaming
- Designed **Star Schema** and implemented **SCD Type 1 & 2**
- Used Unity Catalog for governance and access control

</details>

---

## ğŸ“œ Certifications

- ğŸ… Microsoft Certified: **Fabric Data Engineer Associate (DP-700)**
- ğŸ… Databricks Certified: **Data Engineer Associate**
- ğŸ… HackerRank Certified: **Python**
- ğŸ… HackerRank Certified: **SQL**

---

## ğŸ“ˆ Current Focus

- ğŸ” Solving **5 logic-based problems daily**
- ğŸ§  Strengthening problem-solving & DSA fundamentals
- âš™ï¸ Building production-ready, scalable data architectures
- â˜ï¸ Advancing expertise in **Azure & Databricks**

---

## ğŸ¤ Letâ€™s Connect

ğŸ’¬ Open to:
- Data Engineering roles
- Analytics & Platform Engineering
- Azure / Databricks projects
- Real-world data challenges

ğŸ“© Feel free to connect with me on **LinkedIn** or explore my repositories!

---

â­ *Consistency beats intensity. Learning never stops.*
